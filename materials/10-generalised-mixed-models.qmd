---
title: "Generalised mixed models"
output: html_document
---

```{r}
#| echo: false
#| message: false
#| results: hide
source(file = "setup_files/setup.R")
```

This page contains some information, along with a worked example, explaining how to fit and interpret generalised mixed effects models in `lme4`. 

There are no exercises, but we will work through a dataset you'll recognise from earlier in the course as an example of the code.

::: {.callout-tip}
#### Prior knowledge

These bonus materials are intended to follow on from the materials and concepts introduced in our sister course on [generalised linear modelling](https://cambiotraining.github.io/stats-glm/), and will assume knowledge and familiarity with generalised linear models.
:::

## Libraries and functions

::: {.callout-note collapse="true"}
## Click to expand

We'll need several packages, including the new `glmmTMB`, to explore fitting generalised linear mixed models.

```{r}
#| eval: false
library(performance)
library(glmmTMB)
```
:::

## Generalising linear models

One of the assumptions of a linear model is that the response variable is continuous. But in many real experiments, the response variable might be one of the following:

- binary (yes/no or success/fail)
- proportional (number of successes out of all trials)
- fractional (percentage of a quantity)
- count (integers with a lower limit at 0)

or might follow a strongly non-normal distribution, e.g., time or income often follow an exponential distribution.

In these cases, a linear model may not be appropriate, and/or a generalised linear model can provide a better fit. GLMs "extend" the standard linear model by wrapping the linear equation inside a non-linear link function. 

### Extending linear mixed effects models

Very usefully, the procedure that we apply to generalise a standard linear model - namely, adding a link function - also works to generalise linear mixed effects models.

By including both a link function and one or more random effects, we can combine two extensions to the linear model to create generalised linear mixed effects models (GLMMs).

The assumptions of a GLMM are an amalgamation of the assumptions of a GLM and a linear mixed model:

- Independent observations (after random effects)
- Response variable follows distribution from exponential family (binomial, Poisson, beta, gamma, etc.)
- Correct link function; there is a linear relationship between the linearised model
- Normally distributed random effects

## Revisiting Arabidopsis

To give an illustration of how we fit and assess generalised linear mixed effects models (GLMMs), we'll look at the internal dataset `Arabidopsis`, which we investigated earlier in the course in [Exercise -@sec-exr_arabidopsis].

::: {.panel-tabset group="language"}
## R
```{r}
data("Arabidopsis")
```
:::

In this dataset, there are eight variables:

- `total.fruits`, an integer variable measuring the total fruits produced per plant
- `amd`, a variable measuring whether the plant underwent simulated herbivory (clipped or unclipped)
- `nutrient`, a variable measuring which type of fertiliser/treatment the plant received (1, minimal or 8, added)
- `reg`, or region, a variable with three categories (NL Netherlands, SP Spain, SW Sweden)
- `popu`, or population, a variable representing groups within the regions
- `gen`, or genotype, a variable with 24 categories
- `rack`, a "nuisance" or confounding factor, representing which of two greenhouse racks the plant was grown on
- `status`, another nuisance factor, representing the plant's germination method (Normal, Petri.Plate or Transplant)

We're interested in finding out whether the fruit yield can be predicted based on the type of fertiliser and whether the plant underwent simulated herbivory, across different genotypes and populations.

In the previous section of the course on checking assumptions, we fitted a standard linear mixed model to these data. Here, we'll fit a slightly simplified version:

::: {.panel-tabset group="language"}
## R
```{r}
lme_arabidopsis <- lmer(total.fruits ~ nutrient + amd + (1|popu) + (1|gen), 
                        data = Arabidopsis)

summary(lme_arabidopsis)
```
:::

But we found that the diagnostic plots for this model did not look good, in particular the residual vs fitted, location-scale, normal Q-Q and posterior predictive check plots:

::: {.panel-tabset group="language"}
## R
```{r}
check_model(lme_arabidopsis, 
            check = c("linearity", "homogeneity", "qq", "pp_check"))
```
:::

You may have spotted the reason for this when you completed the exercise in section 7 of this course: `total.fruits` is not a continuous response variable, but instead a count variable.

We want to improve the way that we're modelling this variable by including a link function.

### The glmer function

Since `total.fruits` is a count variable, so we should consider a model that uses a discrete distribution, instead of the normal distribution we've been assuming so far. We can start with the Poisson distribution, which is the simplest of the commonly-used count distributions.

We do this in `lme4` using the `glmer` function (the `g` in the function name is for "generalised"). It combines the syntax that you're already used to from `lmer`, with the syntax from the standard `glm` function in base R. In other words, we keep all the same syntax for random effects, and we include the `family` argument to determine which link function we're using.

::: {.panel-tabset group="language"}
## R
```{r}
glmm_arabidopsis <- glmer(total.fruits ~ nutrient + amd + (1|popu) + (1|gen), 
                          data = Arabidopsis, family = "poisson")

summary(glmm_arabidopsis)
```
:::

Some brief points of comparison between this model summary, and the summary for `lme_arabidopsis` above. 

Firstly, you'll see the GLMM has been fitted using maximum likelihood estimation rather than ReML. Secondly, you'll also see that there are some p-values provided as standard in the GLMM output; these are called Wald tests, which test whether the coefficient value is significantly different from zero (this is subtly different from testing whether the individual predictor itself is significant).

Let's have a look at the diagnostic plots, and see if we've made any improvements on our standard linear mixed model.

::: {.panel-tabset group="language"}
## R
```{r}
check_model(glmm_arabidopsis, residual_type = "normal",
            check = c("pp_check", "outliers", "reqq"))
```
:::

We have one potentially influential point we might want to investigate, which has a Cook's distance > 0.8. (Note that you can also use the `check_outliers` function if you find the plot above a little difficult to interpret, or if you want to change the threshold.)

Our random effects do appear to be nicely normally distributed.

The posterior predictive check, however, raises some concerns. The blue simulated values don't really appear to be following the pattern of the data (green), especially on the left hand side of the plot.

::: {.panel-tabset group="language"}
## R
```{r}
check_model(glmm_arabidopsis, residual_type = "normal",
            check = c("vif", "overdispersion"))

check_overdispersion(glmm_arabidopsis)
```
:::

Well, we're fine on collinearity, but overdispersion/zero-inflation seems a huge problem, especially when we use the `check_overdispersion` function to investigate in more detail. It seems that the Poisson distribution actually isn't representative of our response variable.

### Negative binomial regression

We can, instead of Poisson regression, try fitting a negative binomial regression instead. As with standard GLMs, this requires a slightly different function - `glmer.nb` rather than `glmer`.

::: {.panel-tabset group="language"}
## R
```{r}
glmmnb_arabidopsis <- glmer.nb(total.fruits ~ nutrient + amd + (1|popu) + (1|gen), 
                               data = Arabidopsis)

summary(glmmnb_arabidopsis)
```
:::

If we check the diagnostic plots, we can see a bit of improvement - the posterior predictive check in particular looks much better.

::: {.panel-tabset group="language"}
## R
```{r}
check_model(glmmnb_arabidopsis, residual_type = "normal",
            check = c("pp_check", "outliers", "reqq"))

check_model(glmmnb_arabidopsis, residual_type = "normal",
            check = c("vif", "overdispersion"))

check_overdispersion(glmmnb_arabidopsis)
```
:::

It could still be better; there's evidence now for underdispersion. 

The lingering issues might be because of zero-inflation. If we look at the distribution of the data via a histogram, this certainly looks plausible.

::: {.panel-tabset group="language"}
## R
```{r}
ggplot(data = Arabidopsis, aes(x = total.fruits)) +
  geom_histogram()
```
:::

What are the next steps in improving this analysis?

Well, we could fit a zero-inflated model to these data. Because zero-inflated models are a bit more complex - you're actually fitting two different models or distributions simultaneously to the same dataset - `lme4` unfortunately doesn't contain a function that allows us to do this.

If you need to go beyond the standard array of distributions that are offered in `glm` and `glmer`, such as fitting a zero-inflated model, you have to explore other R packages. To help guide you, there is a brief description in the next session of some possible options. 

## Alternative packages

Though we have focused heavily on `lme4` in this course, and for this section on GLMMs, it's important to flag to you that this is not the *only* package for fitting generalised mixed effects models (or linear mixed effects models, as it happens).

### The glmmTMB package

This package is designed explicitly for generalised mixed effects modelling in R (and somewhat as an extension to `lme4`, so the syntax isn't too unfamiliar). 

You can find a manual for the `glmmTMB` package written by the author [here](https://cran.r-project.org/web/packages/glmmTMB/vignettes/glmmTMB.pdf) that contains more information and code examples.

How might we use the package to fit a zero-inflated Poisson model for the `Arabidopsis` dataset?

::: {.panel-tabset group="language"}
## R
```{r}
glmmzip_arabidopsis <- glmmTMB(total.fruits ~ nutrient + rack + status + amd + reg + 
                          (1|popu) + (1|gen), data = Arabidopsis,
                          family = "poisson", ziformula = ~1)

summary(glmmzip_arabidopsis)
```
:::

The new bit of syntax is the `ziformula` argument. If you set this equal to `~0`, you are asking R to estimate the model *excluding* zero-inflation (which is also the default). So, to model the zero-inflation, you must set this argument equal to `~1`.

We could look at all the diagnostic plots (and in a real analysis situation, you would), but let's focus on the posterior predictive check.

::: {.panel-tabset group="language"}
## R
```{r}
check_model(glmmzip_arabidopsis, residual_type = "normal", check = "pp_check")
```
:::

It's doing a much, much better job now of estimating those zeroes (top left of the plot). However, it's suffering from similar problems to our original Poisson model in the range around 1-15.

Perhaps a zero-inflated negative binomial model might do the trick for the `Arabidopsis` dataset? We can fit that in `glmmTMB` by updating the `family` argument.

::: {.panel-tabset group="language"}
## R
```{r}
glmmzinb_arabidopsis <- glmmTMB(total.fruits ~ nutrient + rack + status + amd + reg + 
                          (1|popu) + (1|gen), data = Arabidopsis,
                          family = "nbinom2", ziformula = ~1)

check_model(glmmzinb_arabidopsis, residual_type = "normal", check = "pp_check")
```
:::

Not perfect - but perhaps better?

### Even more packages

Even `glmmTMB` is not the end of the road. There are others one could use, including packages such as `brms` and `GLMMadaptive`, or the `glmmPQL` function from `MASS`, and you may see these cropping up in online tutorials or even papers.

For a detailed list of packages, [this resource](https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#which-r-packages-functions-fit-glmms) from Bolker et al. is a great starting point.

A note of caution: not all packages will implement exactly the same computational methods "under the hood" as `lme4`, because fitting and assessing mixed effects models, especially non-linear and generalised ones, is difficult to do and therefore is still an area of active research and discussion in statistics. 

So, if you notice that you get different estimates and numbers when fitting models in different packages, don't panic. What matters more than anything is the conclusion you draw from your data overall, and how confident you are in that conclusion.

For those of you with an interest in the computational side of things, you might find resources such as [this blog post](https://rpubs.com/kaz_yos/glmm1) to be a useful starting place.

## Summary

Linear mixed effects models can be generalised in the same way that standard linear models are: by wrapping the linear equation inside a non-linear link function. The link function is chosen based on the distribution of the response variable.

Alternatively, you might prefer to think of it the other way around: that GLMs can be extended to cope with non-independence by adding random effects to them. In either case, the result is the same. Both random effects and link functions can be used simultaneously, to cope with the (quite common!) situation where a dataset is both hierarchical and has a non-continuous response variable.

::: {.callout-tip}
#### Key points
- By including both a link function to linearise the model, and random effects, we can fit generalised linear mixed effects models in R
- We can do this by using the `glmer` or `glmer.nb` functions from `lme4` for most of the "common" GLMMs
- Other packages such as `glmmTMB` are needed for zero-inflated models and other extensions
- Evaluating and assessing GLMMs can be done using the same methods as for standard GLMs/linear mixed effects models
:::

