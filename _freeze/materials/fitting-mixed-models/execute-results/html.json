{
  "hash": "7a1618a0f550604c65fb502fcacdcfed",
  "result": {
    "markdown": "---\ntitle: \"Fitting mixed models\"\noutput: html_document\n---\n\n::: {.cell}\n\n:::\n\n\nThe course materials so far have discussed the motivation behind mixed effects models, and why we might choose to include random effects.\n\nIn this section, we will learn how to fit these models in R, and how to visualise the results.\n\n## Libraries and functions\n\n::: {.callout-note collapse=\"true\"}\n## Click to expand\n\nWe'll be using the `lme4` package in R, which is by far the most common and best choice of package for this type of model. (It's an update of the older package `nlme`, which you might also see people using.) The syntax is nice and simple and extends what we've been doing so far with the `lm()` function in (hopefully!) a very intuitive way. \n\nThe package also contains functions for fitting non-linear mixed effects and generalised mixed effects models - though we won't be focusing on those here, it's nice to know that the package can handle them in case you ever choose to explore them in future!\n\nFor Python users, the `pymer4` package in Python allows you to \"borrow\" most of the functionality of R's `lme4`, though it still has many bugs that make it difficult to run on any system except Linux. There is also some functionality for fitting mixed models using `statsmodels` in Python. We won't be using those packages here, but you may wish to explore them if you are a die-hard Python user!\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load the required packages for fitting & visualising\nlibrary(tidyverse)\nlibrary(lme4)\nlibrary(broom)\nlibrary(broom.mixed)\n```\n:::\n\n:::\n\n## The sleepstudy data\n\nWe'll be using the internal `sleepstudy` dataset from the `lme4` package in R as an example (this dataset is also provided as a `.csv` file, if you'd prefer to read it in or are using Python). \n\nThis is a simple dataset taken from a real study that investigated the effects of sleep deprivation on reaction times in 18 subjects, and has just three variables: `Reaction`, reaction time in milliseconds; `Days`, number of days of sleep deprivation; and `Subject`, subject ID.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"sleepstudy\")\n\nhead(sleepstudy)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Reaction Days Subject\n1 249.5600    0     308\n2 258.7047    1     308\n3 250.8006    2     308\n4 321.4398    3     308\n5 356.8519    4     308\n6 414.6901    5     308\n```\n:::\n:::\n\n\nHave a look at the data more closely. You'll notice that for each subject, we've got 10 measurements, one for each day of sleep deprivation. This repeated measurement means that our data are not independent of one another; for each subject in the study we would expect measurements of reaction times to be more similar to one another than they are to reaction times of another subject.\n\nLet's start by doing something that we know is wrong, and ignoring this dependence for now. We'll begin by visualising the data with a simple scatterplot.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(sleepstudy, aes(x = Days, y = Reaction)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n```\n\n::: {.cell-output-display}\n![](fitting-mixed-models_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\nThis gives the overall impression that we might expect - reaction time does seem to slow as people become more sleep deprived.\n\nBut, as we've already pointed out, ignoring the fact that subjects' own reaction times will be more similar to themselves than to another subject's, we should make a point of accounting for this.\n\n## Adding a random effect\n\nIn this dataset, we want to treat `Subject` as a random effect, which means fitting a mixed effects model. Why `Subject`? There are two things at play here that make us what to treat this as a random effect:\n\n1. `Subject` is a *grouping* variable within our dataset, and is causing us problems with independence.\n2. It's not these specific 18 subjects that we're interested in - they instead represent 18 random selections from a broader distribution/population of subjects that we could have tested. We would like to generalise our findings to this broader population.\n\nTo fit the model, we use a different function to what we've used so far, but the syntax looks very similar. The difference is the addition of a new term `(1|Subject)`, which represents our random effect.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# construct a linear mixed effects model with Subject\n# as a random effect\nlme_sleep1 <- lmer(Reaction ~ Days + (1|Subject),\n                   data = sleepstudy)\n\n# summarise the model\nsummary(lme_sleep1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: Reaction ~ Days + (1 | Subject)\n   Data: sleepstudy\n\nREML criterion at convergence: 1786.5\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.2257 -0.5529  0.0109  0.5188  4.2506 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n Subject  (Intercept) 1378.2   37.12   \n Residual              960.5   30.99   \nNumber of obs: 180, groups:  Subject, 18\n\nFixed effects:\n            Estimate Std. Error       df t value Pr(>|t|)    \n(Intercept) 251.4051     9.7467  22.8102   25.79   <2e-16 ***\nDays         10.4673     0.8042 161.0000   13.02   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\nDays -0.371\n```\n:::\n:::\n\nOkay. The syntax might have looked similar to a standard linear model, but the output does not.\n\nIn later sections of the course, we'll discuss how to test significance based on this sort of output. In the meantime, however, to help get our head around the model we've fitted, we're going to visualise it.\n\nHere, we'll make use of the `broom` and `broom.mixed` packages to extract fitted values from the models.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create a linear model - we'll use this in our graph\nlm_sleep <- lm(Reaction ~ Days,\n               data = sleepstudy)\n\n# set up our basic plot\nggplot(sleepstudy, aes(x = Days, y = Reaction)) +\n  \n  # create separate plots for each subject in the sample\n  # and add the data points\n  facet_wrap(facets = vars(Subject), nrow = 3) +\n  geom_point() +\n  \n  # this adds the line of best fit for the whole sample\n  # (without the random effect), using coefficients\n  # from our simple linear model object\n  geom_line(data = augment(lm_sleep), aes(y = .fitted)) + \n  \n  # and finally, this will add different lines of best fit\n  # for each subject as calculated in our mixed model object\n  geom_line(data = augment(lme_sleep1), aes(y = .fitted), \n            colour = \"blue\")\n```\n\n::: {.cell-output-display}\n![](fitting-mixed-models_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\nEach plot represents a different subject's data. On each plot, we've added the following:\n\n* in black we have the same overall line of best fit from our original (incorrect) linear model.\n* in blue are the individual lines of best fit for each subject. These lines move up and down the plot relative to the global line of best fit. This reflects the fact that, though all subjects are declining as they become more sleep deprived, some of them started with slower baseline reaction times, with different y-intercepts to match. Subject 310, for instance, seems to have pretty good reflexes relative to everyone else, while subject 337 isn't quite as quick on the trigger.\n\nThe eagle-eyed among you, though, might have spotted that the *gradient* of each of these blue lines is still the same as the overall line of best fit. This is because we've added a random intercept in our model, but have **kept the same slope**. \n\nThis reflects an underlying assumption that the relationship between sleep deprivation and reaction time is the same - i.e. that people get worse at the same rate - even if their starting baselines differ.\n\nWe might not think that this assumption is a good one, however. And that's where random slopes come in.\n\n## Adding random slopes and random intercepts\n\nTo add a random slope as well as a random intercept, we need to alter the syntax slightly for our random effect. Now, instead of `(1|Subject)`, we'll instead use `(1 + Days|Subject)`. This allows the relationship between `Days` and `Reaction` to vary between subjects.\n\nLet's fit that new model and summarise it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlme_sleep2 <- lmer(Reaction ~ Days + (1 + Days|Subject),\n                   data = sleepstudy)\n\nsummary(lme_sleep2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: Reaction ~ Days + (1 + Days | Subject)\n   Data: sleepstudy\n\nREML criterion at convergence: 1743.6\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.9536 -0.4634  0.0231  0.4634  5.1793 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr\n Subject  (Intercept) 612.10   24.741       \n          Days         35.07    5.922   0.07\n Residual             654.94   25.592       \nNumber of obs: 180, groups:  Subject, 18\n\nFixed effects:\n            Estimate Std. Error      df t value Pr(>|t|)    \n(Intercept)  251.405      6.825  17.000  36.838  < 2e-16 ***\nDays          10.467      1.546  17.000   6.771 3.26e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\nDays -0.138\n```\n:::\n:::\n\nWe can go ahead and add our new lines (in red) to our earlier facet plot:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(sleepstudy, aes(x = Days, y = Reaction)) +\n  facet_wrap(facets = vars(Subject), nrow = 3) +\n  geom_point() +\n  \n  # the global line of best fit\n  geom_line(data = augment(lm_sleep), aes(y = .fitted)) + \n  \n  # our previous lines of best fit, with random intercepts\n  # but constant slope\n  geom_line(data = augment(lme_sleep1), aes(y = .fitted), \n            colour = \"blue\") +\n  \n  # our lines of best with random intercepts and random slopes\n  geom_line(data = augment(lme_sleep2), aes(y = .fitted), \n            colour = \"red\") \n```\n\n::: {.cell-output-display}\n![](fitting-mixed-models_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\nWhile for some of our subjects, the red, blue and black lines look quite similar, for others they diverge a fair amount. Subjects 309 and 335, for instance, are displaying a remarkably flat trend that suggests they're not really suffering delays in reaction time from their sleep deprivation very much at all, while subject 308 definitely seems to struggle without their eight hours. \n\n## Fitting random slopes without random intercepts\n\nIt's quite unusual to fit a model with random slopes but without random intercepts - but it's absolutely possible.\n\nThe `lme4` package includes \"implicit random intercepts\", meaning that we don't actually need to specify the 1 in our random effects structure for random intercepts to be fitted. \n\nTry running the following, and compare the two outputs - these models are indentical:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlme_explicit <- lmer(Reaction ~ Days + (1 + Days|Subject),\n                   data = sleepstudy)\n\nsummary(lme_explicit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: Reaction ~ Days + (1 + Days | Subject)\n   Data: sleepstudy\n\nREML criterion at convergence: 1743.6\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.9536 -0.4634  0.0231  0.4634  5.1793 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr\n Subject  (Intercept) 612.10   24.741       \n          Days         35.07    5.922   0.07\n Residual             654.94   25.592       \nNumber of obs: 180, groups:  Subject, 18\n\nFixed effects:\n            Estimate Std. Error      df t value Pr(>|t|)    \n(Intercept)  251.405      6.825  17.000  36.838  < 2e-16 ***\nDays          10.467      1.546  17.000   6.771 3.26e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\nDays -0.138\n```\n:::\n\n```{.r .cell-code}\nlme_implicit <- lmer(Reaction ~ Days + (Days|Subject),\n                   data = sleepstudy)\n\nsummary(lme_implicit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: Reaction ~ Days + (Days | Subject)\n   Data: sleepstudy\n\nREML criterion at convergence: 1743.6\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.9536 -0.4634  0.0231  0.4634  5.1793 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr\n Subject  (Intercept) 612.10   24.741       \n          Days         35.07    5.922   0.07\n Residual             654.94   25.592       \nNumber of obs: 180, groups:  Subject, 18\n\nFixed effects:\n            Estimate Std. Error      df t value Pr(>|t|)    \n(Intercept)  251.405      6.825  17.000  36.838  < 2e-16 ***\nDays          10.467      1.546  17.000   6.771 3.26e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\nDays -0.138\n```\n:::\n:::\n\nIf we were determined to remove the random intercepts, we have to explicitly tell `lme4` not to fit them, like this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlme_slopesonly <- lmer(Reaction ~ Days + (0 + Days|Subject),\n                   data = sleepstudy)\n\nsummary(lme_slopesonly)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: Reaction ~ Days + (0 + Days | Subject)\n   Data: sleepstudy\n\nREML criterion at convergence: 1766.5\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.5104 -0.5588  0.0541  0.6244  4.6022 \n\nRandom effects:\n Groups   Name Variance Std.Dev.\n Subject  Days  52.71    7.26   \n Residual      842.03   29.02   \nNumber of obs: 180, groups:  Subject, 18\n\nFixed effects:\n            Estimate Std. Error     df t value Pr(>|t|)    \n(Intercept)   251.41       4.02 161.00  62.539  < 2e-16 ***\nDays           10.47       1.87  21.68   5.599 1.32e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\nDays -0.340\n```\n:::\n:::\n\nYou should see that the random intercepts have now disappeared from the output.\n\n## Two-level models\n\nBoth of the two models that we've fitted so far to these data (with and without the random slopes) can both be described as two-level models.\n\nA standard linear model would be a one-level model, where we have independence in our dataset and no natural clustering/grouping variables.\n\nBut for this dataset, the `Reaction` variable is clustered within the `Subject` variable. Whether we choose to fit random intercepts, slopes, or both, this overall structure remains the same: one variable nested inside another, creating a hierarchy with two levels. Hence, a two-level model!\n\nLater in the course, we will look at more complicated models, where we have three or more levels, or where our variables are not completely nested inside each other, due to a more complex experimental design.\n\n## Partial pooling & shrinkage\n\nWhile we're working with this dataset, let's take the opportunity to visualise something else that's special about random effects (which we'll discuss more later in the course): shrinkage.\n\nAs an extra observation, let's use `geom_smooth` to add the lines of best fit that we would see if we fitted each subject with their own individual regression:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(sleepstudy, aes(x = Days, y = Reaction)) +\n  facet_wrap(facets = vars(Subject), nrow = 3) +\n  geom_point() +\n  \n  # the global line of best fit\n  geom_line(data = augment(lm_sleep), aes(y = .fitted)) + \n  \n  # random slopes only\n  geom_line(data = augment(lme_sleep1), aes(y = .fitted), \n            colour = \"blue\") +\n  \n  # random intercepts and random slopes\n  geom_line(data = augment(lme_sleep2), aes(y = .fitted), \n            colour = \"red\") +\n  \n  # individual regression lines for each individual\n  geom_smooth(method = \"lm\", se = FALSE,\n              colour = \"green\", linewidth = 0.5)\n```\n\n::: {.cell-output-display}\n![](fitting-mixed-models_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\nHere, the black line (which is the same on every plot) represents a global line of best fit - this is what we would see using **complete pooling**.\n\nThe green lines, meanwhile, represent what happens when we allow **no pooling**. In other words, we've fit individual regressions between `Reaction` and `Days` for each subject, treating each subject as a completely separate dataset.\n\nThe blue and red lines represent our mixed effects models - the difference between the two is whether we allowed the slope to vary randomly, as well as the random intercept. In both cases, we are using something called **partial pooling**. \n\nComparing the green and red lines allows us to see the phenomenon of \"shrinkage\". The red lines are all closer to the black line than the green line is; in other words, there's some shrinkage towards the global line (Subjects 330, 335 and 370 perhaps show this best.) \n\nThis happens because, when random effects are estimated, information is shared between the different levels of the random effect (in this case, between subjects). Though we still estimate separate slopes and/or intercepts for each subject, we take into account the global average, and this pulls the individual lines of best fit towards the global one.\n\n## Exercise\n\nRead in the `dragons.csv` file, explore these data, then fit, summarise and visualise at least one mixed effects model in the same way that we did for the `sleepstudy` data.\n\nThere are five different variables in the `dragons` dataset:\n\n- `dragon`, which is simply an ID number for each dragon measured; here, each dragon is unique\n- `wingspan`, a measure of the size of the dragon\n- `scales`, a categorical (binary) variable for what colour scales the dragon has\n- `mountain`, a categorical variable representing which mountain range the dragon was found on\n- `intelligence`, our continuous response variable\n\nWe're interested in the relationships between `wingspan`, `scales` colour and `intelligence`, but we want to factor in the fact that we have measured these variables across 5 different mountain ranges.\n\nAs a slightly more complicated dataset (with more variables), there are more possible models that could be fitted. Think about: what different structures might the fixed and random effects take? How does that change our visualisation?\n\nTry to work through this yourself, before expanding the answer below.\n\n::: {.callout-note collapse=\"true\"}\n#### Worked answer\n\nHere, we'll work through how to fit and visualise one possible mixed effects model that could be fitted to these data.\n\nBut, if you fitted models with other sets of fixed/random effects and explored those, well done. We'll talk in the next section of the course about how you can decide between these models to determine which is the best at explaining the data. Right now, it's just the process that matters.\n\n#### Step 1: Visualise your data\n\nBefore we do anything else, let's have a look at what we're working with:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndragons <- read_csv(\"datasets/dragons.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 200 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): scales, mountain\ndbl (3): dragon, wingspan, intelligence\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nhead(dragons)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 5\n  dragon wingspan scales    intelligence mountain\n   <dbl>    <dbl> <chr>            <dbl> <chr>   \n1      1     69.7 chromatic         136. A       \n2      2     33.3 metallic          122. A       \n3      3     50.4 chromatic         109. A       \n4      4     32.0 metallic          109. A       \n5      5     84.7 chromatic         124. A       \n6      6     38.8 metallic          117. A       \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(dragons, aes(x = wingspan, y = intelligence, colour = scales)) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](fitting-mixed-models_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(dragons, aes(x = scales, y = intelligence)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](fitting-mixed-models_files/figure-html/unnamed-chunk-13-2.png){width=672}\n:::\n:::\n\nAs a whole, we get the impression that as wingspan increases, so does intelligence. It also looks as if intelligence is slightly higher on average in metallic dragons than in chromatic dragons.\n\nMight there be an interaction between `wingspan` and `scales`? It's hard to tell from our first plot, but it's not impossible. (You could try using the `geom_smooth` function to fit a basic grouped linear regression, if you wanted a clearer idea at this stage.)\n\nNow, let's produce the same plots, but faceted/split by mountain range:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(dragons, aes(x = wingspan, y = intelligence, colour = scales)) +\n  facet_wrap(vars(mountain)) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](fitting-mixed-models_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(dragons, aes(x = scales, y = intelligence)) +\n  facet_wrap(vars(mountain)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](fitting-mixed-models_files/figure-html/unnamed-chunk-14-2.png){width=672}\n:::\n:::\n\nThe broad impression remains the same, but for one thing: the strength of the relationship between `wingspan` and `intelligence` seems to vary across our different facets, i.e. between mountain ranges. \n\nIt's hard to tell whether the relationship between `scales` and `intelligence` also differs across mountain ranges, as this effect is subtler overall.\n\n#### Step 2: Consider our fixed effects \n\nWe have four options for our fixed effects structure:\n\n- No fixed effects (a random effects only model)\n- A single effect, of either `wingspan` or `scales`\n- An additive model\n- Including both main effects and an interaction\n\nWe'll talk in the next section of the course about how we can compare between different models and determine whether individual predictors are significant or not.\n\nHowever, in this case we want to fit at least an additive fixed effects structure, as the exercise summary indicated that we are interested in whether `scales` and `wingspan` have a bearing on `intelligence`. For this walkthrough, we'll include the interaction term as well.\n\n#### Step 3: Consider our random effects\n\nThere is only one variable in this dataset that it would be suitable to consider \"random\": `mountain`. And, given how the plots look when we split them by mountain range, it would seem that this is very much something we want to take into account.\n\n(The `wingspan` variable is continuous, and the categorical `scales` variable only contains two levels, making both of these inappropriate/impossible to treat as random variables.)\n\nHowever, as we learned by looking at the `sleepstudy` dataset, we can fit multiple separate random effects, meaning that even with just `mountain` as a clustering variable, we have options!\n\n- Random intercepts, by mountain; `(1|mountain)`\n- Random slopes for `wingspan`, by mountain; `(0 + wingspan|mountain)`\n- Random slopes for `scales`, by mountain; `(0 + scales|mountain)`\n- Random slopes for `wingspan:scales`, by mountain; `(0 + wingspan:scales|mountain)`\n\n::: {.callout-tip}\nThis last option is worth taking a moment to unpack. \n\nAllowing `wingspan:scales` to vary by mountain means that we are asking the model to assume that the strength of the interaction between `wingspan` and `scales` varies between mountain ranges such that the different coefficients for that interaction are drawn from a random distribution.\n\nOr, phrased differently: the strength of the relationship between `wingspan` and `intelligence` depends on `scales` colour, but the degree to which it is dependent on `scales` colour also varies between `mountain` ranges.\n\nThis is biologically plausible! Though, we're dealing with imaginary creatures, so one could facetiously claim that *anything* is biologically plausible...\n:::\n\nAgain, the next section of the course will talk about how we can compare models to decide which predictors (including random effects) are making useful contributions to our model.\n\nIt would be perfectly allowable for you to fit all four of these random effects if you wanted to. The syntax to include them all would be `(1 + wingspan*scales|mountain)`, or written out in full, `(1 + wingspan + scales + wingspan:colour|mountain)`.\n\nFor now, though, we'll just fit the first two random effects (random intercepts, and random slopes for `wingspan`, by `mountain`), to keep things a little simpler.\n\n#### Step 4: Fit the model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlme_dragons <- lmer(intelligence ~ wingspan*scales + (1 + wingspan|mountain), \n                    data=dragons)\nsummary(lme_dragons)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: intelligence ~ wingspan * scales + (1 + wingspan | mountain)\n   Data: dragons\n\nREML criterion at convergence: 1629.3\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.56346 -0.66381  0.04359  0.69979  2.56843 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr\n mountain (Intercept)  10.4730  3.2362      \n          wingspan      0.2629  0.5127  0.09\n Residual             181.4417 13.4700      \nNumber of obs: 200, groups:  mountain, 5\n\nFixed effects:\n                         Estimate Std. Error        df t value Pr(>|t|)    \n(Intercept)              89.28519    3.73223  10.69540  23.923 1.24e-10 ***\nwingspan                  1.00255    0.23620   4.22265   4.244  0.01177 *  \nscalesmetallic           15.67710    4.81498 188.76548   3.256  0.00134 ** \nwingspan:scalesmetallic  -0.09228    0.07976 188.37980  -1.157  0.24878    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) wngspn sclsmt\nwingspan    -0.168              \nscalesmtllc -0.649  0.155       \nwngspn:scls  0.590 -0.167 -0.918\n```\n:::\n:::\n\nThis output looks very similar to what we saw before. The main difference here is that our fixed effect structure is more complex than for the `sleepstudy` dataset - hence, we have two additional rows, for our second main effect and our interaction. (The correlation matrix for our fixed effects, right at the bottom, has also become more complicated.)\n\n#### Step 5: Visualise the model\n\nWe'll start by building a plot that's faceted by `mountain`, since we know this is a crucial clustering variable. To add our mixed model to the plot, we use the `augment` function from the `broom.mixed` package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(dragons, aes(wingspan, intelligence, colour = scales)) +\n  facet_wrap(vars(mountain)) +\n  geom_point() +\n  # use augment so that we can plot our mixed model\n  geom_line(data = augment(lme_dragons), aes(y = .fitted))\n```\n\n::: {.cell-output-display}\n![](fitting-mixed-models_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\nIf we wanted to visually compare our model to others that we could have fitted, we can include them on the same plot.\n\nHere, we're adding a) the results of a standard linear model, which will be the same across every facet, and b) what our mixed model would look like if we hadn't included `scales` or the `wingspan:scales` interaction, for the purposes of comparison:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# construct the models, so we can use the augment function\nlm_dragons <- lm(intelligence ~ wingspan, data = dragons)\nlme_dragons2 <- lmer(intelligence ~ wingspan + (1 + wingspan|mountain),\n                     data = dragons)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nunable to evaluate scaled gradient\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge: degenerate Hessian with 1 negative eigenvalues\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Model failed to converge with 1 negative eigenvalue: -2.6e+00\n```\n:::\n\n```{.r .cell-code}\nggplot(dragons, aes(x = wingspan, y = intelligence, colour = scales)) +\n  facet_wrap(vars(mountain)) +\n  geom_point() +\n  geom_line(data = augment(lme_dragons), aes(y = .fitted))+\n  \n  #standard linear model\n  geom_line(data = augment(lm_dragons), aes(y = .fitted),\n            colour = \"black\") +\n  \n  #mixed model with only wingspan as fixed effect\n  geom_line(data = augment(lme_dragons2), aes(y = .fitted), \n            colour = \"green\")\n```\n\n::: {.cell-output-display}\n![](fitting-mixed-models_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n:::\n\n## Summary\n\nThis section of the course is designed to introduce the syntax that's required for fitting 2-level mixed models in R, including both random intercepts and random slopes, and how we can visualise the resulting models.\n\nLater sections will address significance testing and assumption checking, as well as how to fit more complex mixed models.\n\n::: callout-note\n#### Key points\n- Mixed effects models can be fitted using the `lme4` package in R, which extends the linear model by introducing specialised syntax for random effects\n- For random intercepts, we use the format `(1|B)`, where B is our grouping variable\n- For random intercepts with random slopes, we use the format `(1 + A|B)`, where we allow the slope of A as well as the intercept to vary between levels of B\n- For random slopes only, we use `(0 + A|B)`, which gives random slopes for A without random intercepts\n- Random effects are fitted using partial pooling, which results in the phenomenon of \"shrinkage\"\n:::",
    "supporting": [
      "fitting-mixed-models_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}